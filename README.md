作业①
#第一次上传，代码可以在jupyter运行，但pycharm运行报错，尝试解决

#第二次上传，代码已修正，在pycharm可以正常运行，图片输出无误。

#第三次上传，修正图片过于冗余，将同类型图片汇总到一幅图片

#第四次上传，汇集代码思路

①加载并清洗数据，处理缺失值和重复值。
②使用箱线图检查数值特征的异常值，并对数据进行独热编码和标准化。
③通过热图分析特征相关性，并应用KMeans聚类算法寻找最佳聚类数，评估聚类效果。
④构建并训练线性回归模型，评估模型性能。
⑤通过可视化实际值与预测值的关系以及分析特征重要性，帮助理解模型输出和特征对目标变量的影响。

作业②
#第一次上传，读取数据集，查看数据集基本信息
#第二次上传，进行回归预测及其可视化

作业③
#在作业二基础上进行完善
#第一次上传
#第二次上传，改进代码文件无法上传到git？
#第三次上传，代码可以正常在practice与主支之间push
完善后的代码文件依然不能上传

作业④
Week4
（1）数据集细节
![img.png](img.png)
①从Date（日期）列的分布来看，不同日期的样本数量差异较大。
例如，在 2016 年 10 月的多个日期（如 10/8/16、10/15/16、10/22/16 等）样本数量较多，都在 170 以上，
而在 2017 年 1 - 5 月以及 2016 年 12 月等部分日期样本数量很少，只有 1 - 2 个。
这种分布的不均衡性可能导致基于日期进行全面、准确分析的困难，例如难以准确评估不同时间段南瓜市场的稳定趋势等情况，
所以在数据中Date列可能没有很多参考价值。
②Type（种类）列中大部分值为缺失值，只有 45 个非空值。
由于数据缺失严重，很难基于此列进行有效的分析，样本量严重不足，无法确定哪种种类样本充分。
③规格为'sml'、'med'、'lge' 的样本数量相对较多，样本比较充分，而 'exjbo' 规格的样本数量很少。
'BOSTON'、'COLUMBIA'、'CHICAGO' 等城市样本数量较多，样本充分，而 'MIAMI' 城市样本数量极少。
产地为 'PENNSYLVANIA'、'MICHIGAN'、'CALIFORNIA' 等地的样本数量较多，样本比较充分，
而像 'FLORIDA'、'TENNESSEE' 等产地样本数量很少。

（2）特征处理
![img_1.png](img_1.png)
红色区域特征（如 Low Price、High Price 等 ）相关系数高（多在 0.95 以上），存在强线性关联；
蓝色区域（如 Grade 与 Price_Diff 等 ）相关系数低（0.3 - 0.45 左右 ），线性关联弱，部分特征（Environment、Quality 等 ）因无填充值，未呈现相关系数。
![img_2.png](img_2.png)
②各模型特征重要性

1）随机森林
![img_5.png](img_5.png)
2）LGBM
![img_6.png](img_6.png)
3）XGboost
![img_7.png](img_7.png)

（3）模型

①评价指标比较（mse，mae，r方）

R^2：衡量模型解释因变量变异的能力，越接近 1 拟合越好，三种模型交叉验证与单次评估得分均高，表现相近。
MAE：反映预测值与真实值平均绝对偏差，数值越小误差越小，可看出不同模型误差表现及两种评估方式差异。
MSE：平方后放大误差影响，同样用于衡量预测准确性，辅助判断模型稳定性。
![img_3.png](img_3.png)
②预测结果比较
![img_4.png](img_4.png)
这张模型预测结果比较图，通过散点展示了随机森林、LGBM和XGBoost三种模型的预测值与真实值的对应关系，并用红色虚线标示出完美预测的理想状态。从图中可见，在真实值较低时，三种模型的预测值都较接近真实值；但随着真实值增大，预测值分布渐趋分散，各模型在不同程度上偏离完美预测线，反映出在高值区域预测误差可能增大，也表明不同模型在不同数值区间各有表现特点，可为模型选择和优化提供直观参考。

③模型评估
![img_8.png](img_8.png)

![img_9.png](img_9.png)

![img_10.png](img_10.png)
④交叉验证
![img_11.png](img_11.png)

![img_12.png](img_12.png)

![img_13.png](img_13.png)
如果单单从指标看模型表现：

1）拟合能力（单次评估）：XGBoost 的 R² 最高（0.977），MSE（172.49 ）、MAE（9.55 ）最低，对训练数据的拟合效果最优；LGBM 次之（R² 0.967 ）；随机森林稍弱（R² 0.956 ）。
2）泛化能力（5 折交叉验证）：XGBoost R²（0.938 ）仍相对领先，MSE（397.39 ）、MAE（13.02 ）也较优，泛化表现最好；LGBM（R² 0.935 ）、随机森林（R² 0.907 ）依次递减，且随机森林交叉验证后误差上升更明显，泛化稳定性弱于前两者 。

XGBoost 在单次拟合和交叉验证下综合表现更优，LGBM 次之，随机森林泛化稳定性需关注。
但是具体情况具体分析，指标只是一种评价标准，不能作为绝对的判断因素。